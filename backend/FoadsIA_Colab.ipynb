{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "header"
      },
      "source": [
        "# üöÄ FoadsIA ‚Äì Backend Production (GPU T4)\n\nEjecuta el **backend completo de FoadsIA** en Google Colab usando GPU **NVIDIA T4**.\n\n## üìã Instrucciones\n1. Runtime ‚Üí Change runtime type ‚Üí GPU (T4)\n2. Ejecuta las celdas **en orden**\n3. Copia la URL p√∫blica de **ngrok** para tu frontend\n\n---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "setup",
        "cellView": "form"
      },
      "source": [
        "# üõ†Ô∏è PASO 1 ‚Äì Configuraci√≥n del Entorno\nimport os, subprocess\nfrom pathlib import Path\n\nREPO_URL = \"https://github.com/Juanpalojime/FoadsIA.git\"\nBASE_DIR = Path(\"/content\")\nREPO_DIR = BASE_DIR / \"FoadsIA\"\nBACKEND_DIR = REPO_DIR / \"backend\"\n\ndef run(cmd): subprocess.run(cmd, shell=True, check=True)\n\nos.chdir(BASE_DIR)\n\nif not REPO_DIR.exists():\n    run(f\"git clone {REPO_URL}\")\nelse:\n    os.chdir(REPO_DIR)\n    run(\"git pull\")\n\nos.chdir(BACKEND_DIR)\n\nrun(\"apt-get update -qq && apt-get install -y -qq ffmpeg libgl1\")\nrun(\"pip install -q -r requirements.txt\")\n\nrun(\"pip install -q flask flask-socketio flask-cors eventlet pyngrok torch torchvision diffusers safetensors openai-whisper insightface onnxruntime-gpu accelerate xformers\")\n\nimport torch\nprint('GPU:', torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'NO GPU')\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "models",
        "cellView": "form"
      },
      "source": [
        "# ‚¨áÔ∏è PASO 2 ‚Äì Descarga de Modelos (Master Loader)\nimport os\nfrom pathlib import Path\n\nos.chdir('/content/FoadsIA/backend')\n\nif Path('master_loader.py').exists():\n    !python master_loader.py\nelse:\n    print('‚ùå No se encontr√≥ master_loader.py')\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "run",
        "cellView": "form"
      },
      "source": [
        "# üöÄ PASO 3 ‚Äì Ejecutar Backend + Ngrok\nfrom pyngrok import ngrok\nimport os, torch, gc\n\nNGROK_TOKEN = \"\"  # coloca aqu√≠ tu token\nPORT = 5000\n\nif NGROK_TOKEN:\n    ngrok.set_auth_token(NGROK_TOKEN)\n\nngrok.kill()\npublic_url = ngrok.connect(PORT, bind_tls=True).public_url\n\nprint('üåê Backend p√∫blico:', public_url)\n\ntorch.cuda.empty_cache()\ngc.collect()\n\nos.chdir('/content/FoadsIA/backend')\n!python app.py\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "footer"
      },
      "source": [
        "---\n## ‚úÖ Backend FoadsIA listo\n\n- Copia la URL de ngrok\n- Con√©ctala a tu frontend\n- No cierres esta pesta√±a\n\n**FoadsIA Team üöÄ**"
      ]
    }
  ]
}